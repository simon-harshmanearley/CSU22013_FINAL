---
title: "CSU22013: Design and implement a dashboard to visualise and compare commit activity for trending repositories on GitHub."
output: html_notebook
---

The following chunk utilises the MIT GitHub API found at, https://github.com/alisoft/github-trending-api#readme (Full license citation to be added). 

The purpose of using this API is to create a list of the top trending repositories on GitHub, to be used later in conjunction with the official GitHub API, which will allow access to the commit data of each individual repository.

The following code firstly accesses the API, and then retrieves a list of the top trending authors and repository names, in order to manually create a list of URLs to the commit data, which the official GitHub API will then use.

A URL to a repositories commit data is as follows:
"https://api.github.com/repos/", repo_author, "/", repo_name, "/commits"

```{r}
library(httr)
library(jsonlite)
library(furrr)
library(shiny)

# Access information on top trending repositories using the MIT GitHub API 
url <- "https://api.gitterapp.com/repositories?since=daily"
response <- GET(url)
repo_data <- content(response)

# Retrieve list of top 10 authors
repo_author <- lapply(repo_data, "[[", 1)
repo_author <- repo_author[1:10]

# Retrieve list of top 10 repository names
repo_name <- lapply(repo_data, "[[", 2)
repo_name <- repo_name[1:10]

# Function which manually creates URL to commit activity of each repository
create_commit_activity_url <- function(repo_author, repo_name){
  paste0("https://api.github.com/repos/", repo_author, "/", repo_name, "/commits")
}

# Create list of URLs to commit activity of top 10 repositories
commit_activity_url <- mapply(create_commit_activity_url, repo_author, repo_name, SIMPLIFY = FALSE)
commit_activity_url_list <- as.character(commit_activity_url)
```

The following chunk concerns the official GitHub API, found at, https://docs.github.com/en/rest?apiVersion=2022-11-28.

Unfortunately there is no header within the API for any kind of 'total commit count', however it is possible to search page-by-page through the commit history. The maximum commits which can be displayed per page is 100. In order to retrieve the total number of commits per repository, I created a function which loops through each page of the commit history, counting up to 100 commits at a time, until there are no more commits left to count. The function does this for the top 10 trending repositories, the list for which was created in the previous chunk. 

Initially, I was calculating the total commits for the top 25 repositories, however this was taking approximately 3 minutes to complete, so I decided to only analyse the top 10 repositories.

The process in my testing takes approximately 30 seconds, however depending on the total number of commits within the top 10 repositories, this could take a longer, or shorter length of time.

```{r}
# Personal Access Token for GitHub API
API_PAT <- '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'
headers <- c(Authorization = paste("Bearer", API_PAT))

# Initialize a list to store total commit counts for each repository
total_commits_list <- list()

# Function to fetch total commits for a URL
fetch_total_commits <- function(commit_activity_url) {
  
  # Set page number to 1, and total commit count to 0
  page <- 1
  total_commits <- 0
  
  # Set max commits shown per page to 100, and loop through each page, counting total number of commits, until there are none left to count
  while (TRUE) {
    commits_url <- paste0(commit_activity_url, "?per_page=100&page=", page)
    
    # Acceess the commit data from specified page of URL using official GitHub API
    response <- GET(commits_url, add_headers(headers))
    commit_data <- content(response)
    
    # Calculate number of commits on page
    commits_on_page <- length(commit_data)
    
    # If there are no commits in repository, exit loop and return total commits as 0
    if (commits_on_page == 0) {
      break
    }
    
    # Add total commits from page to total commit count, and go to next page
    total_commits <- total_commits + commits_on_page
    page <- page + 1
  }
  
  # Return value of total repository commits
  return(total_commits)
}

# Set up parallel processing
plan(multisession, workers = availableCores())

# Fetch total commits concurrently
total_commits_list <- future_map_int(commit_activity_url_list, fetch_total_commits)

# Display the list of total commit counts from each repository URL
print(total_commits_list)
```

The following chunk utilises Shiny, an open source package for R, to build the app which creates and displays the commit data.

At the moment the code creates and displays a sample bar plot, comparing the total number of commits of the top 10 trending repositories. 

```{r}
# Define UI for app which draws barplot 
ui <- fluidPage(
  
  # App title
  titlePanel("Top 10 Trending GitHub Repositories"),
  
  # Output: barplot
  plotOutput(outputId = "bar_chart")
)

# Define server logic required to draw barplot
server <- function(input, output) {
  
  # Render the bar chart
  output$bar_chart <- renderPlot({
    
    # Determine the size of y-axis and add padding
    max_y <- max(total_commits_list) * 1.2
    
    # Create the bar chart using barplot
    barplot(total_commits_list, col = "#007bc2", border = "black", names.arg = repo_name, 
        xlab = "Repository Names in Descending Order from Most Trending to Least Trending",
        ylab = "Total Commits",
        main = "Total Commits for the Top 10 Trending Repositories on GitHub",
        ylim = c(0, max_y))
    
  })
}

# Create Shiny app
shinyApp(ui = ui, server = server)
```
